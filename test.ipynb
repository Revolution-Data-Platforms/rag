{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from backend.llm.baseLLM import Remote_LLM \n",
    "from backend.retrieval.ciena_retreival import CienaRetrieval\n",
    "from backend.embedder.baseEmbedder import baseEmbedder\n",
    "from backend.retrieval.utils import *\n",
    "from backend.retrieval.rereanker import Reranker\n",
    "from langchain.document_loaders import JSONLoader\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = baseEmbedder().embedding_function\n",
    "retriael_kwargs = {\n",
    "    \"threshold\": \"0.8\",\n",
    "    \"k\": 20,\n",
    "    \"embedder\": embedding_function,\n",
    "    \"hybrid\": True,\n",
    "}\n",
    "ciena_retreival = CienaRetrieval(**retriael_kwargs)\n",
    "reranker = Reranker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db():\n",
    "    \"\"\"Load Ciena database.\"\"\"\n",
    "    \n",
    "    dir = './output/'\n",
    "    loaded_data = []\n",
    "    for r, d, f in os.walk(dir):\n",
    "        \n",
    "        for file in f:\n",
    "            # if \"10Aug-BP_Engineering_guide\" in file or \"Blue_Planet_MLA_Cloud_Deployment_Guide\" in file:\n",
    "            if '.json' in file and file != 'structuredData.json':\n",
    "                dir_ = file.split('.')[0] + '.pdf'\n",
    "                file_name = os.path.join(dir, dir_, file)\n",
    "                print(file_name)\n",
    "                try:\n",
    "                    loader = JSONLoader(\n",
    "                        file_path=file_name,\n",
    "                        jq_schema='.[].content[]',\n",
    "                        content_key=\"text\", \n",
    "                        metadata_func=metadata_func)\n",
    "\n",
    "                    loaded_data.extend(loader.load())\n",
    "                    print(f\"Successfully loaded file {file_name}\")\n",
    "                except Exception as e:\n",
    "                    # import pdb; pdb.set_trace()\n",
    "                    print(f\"error in loading  file {file_name}\")\n",
    "                    print(e)\n",
    "\n",
    "    return loaded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(docs):\n",
    "    loaded_data = filter_empty(docs)\n",
    "    loaded_data = filter_redundant(loaded_data)\n",
    "    loaded_data = exclude_toc(loaded_data)\n",
    "    return loaded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_docs(query, docs):\n",
    "    \"\"\"Get relevant documents from Ciena database.\"\"\"\n",
    "    if len(query) == 0 or len(docs) == 0:\n",
    "        return []\n",
    "    ciena_retrieval = CienaRetrieval(**retriael_kwargs)\n",
    "    relevant_docs = ciena_retrieval.get_res(query, docs)\n",
    "    reranked_res = reranker.rerank(query, relevant_docs)\n",
    "    return reranked_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(docs, headers):\n",
    "    if len(headers) == 0:\n",
    "        return [], []\n",
    "    context, sources = ciena_retreival.get_context(docs, headers)\n",
    "    return context, sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text(history, text):\n",
    "    history = history + [(text, None)]\n",
    "    return history, gr.Textbox(value=\"\", interactive=False)\n",
    "\n",
    "def bot(history):\n",
    "    response = \"**That's cool!**\"\n",
    "    history[-1][1] = \"\"\n",
    "    for character in response:\n",
    "        history[-1][1] += character\n",
    "        time.sleep(0.05)\n",
    "        yield history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_get_src_ctx(message, seconds):\n",
    "    query = message\n",
    "    relevant_docs = get_relevant_docs(query, cleaned_db)\n",
    "    rel_headers = relevant_headers(relevant_docs)\n",
    "    rel_headers = [x for x in rel_headers if x != 'Table of Contents ']\n",
    "    context, sources = get_context(loaded_db, rel_headers)\n",
    "    return context, sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_llm_answer(question, ctx, src):\n",
    "    endpoint = \" http://0.0.0.0:8000/answer\"\n",
    "    LLM_kwargs={'max_new_tokens': 500, 'temperature': 0.5}\n",
    "\n",
    "    llm = Remote_LLM(\n",
    "        endpoint=\"http://0.0.0.0:8000/answer\",\n",
    "        generation_config=LLM_kwargs\n",
    "    )\n",
    "    ctx = ctx[len(ctx) // 2:]\n",
    "    if len(ctx) > 2000: \n",
    "        ctx = ctx[:2000]\n",
    "    prompt = f\"\"\"\n",
    "    You are a powerful AI asistant that answers only based on the given contex. If the context is not enough, you can ask for more information.\n",
    "    Given the following context {ctx}, answer the following question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    answer = llm(prompt)\n",
    "    return answer, src\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_echo(message, history):\n",
    "    ctx, src = main_get_src_ctx(message, 3)\n",
    "    # convert list ctx to string\n",
    "    ctx =' '.join(ctx)\n",
    "    answer, src = gt_llm_answer(message, ctx, src)\n",
    "    return answer #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_db = load_db()\n",
    "cleaned_db = clean(loaded_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"give me a table for ciena's BPO Runtime License\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = get_relevant_docs(query, cleaned_db)\n",
    "rel_headers = relevant_headers(relevant_docs)\n",
    "rel_headers = [x for x in rel_headers if x != 'Table of Contents ']\n",
    "context, sources = get_context(loaded_db, rel_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following tables list the licenses to run the software application. \n",
      "Table 3. BPO Runtime Licenses \n",
      "|    | PRODUCT _x000D_             | PART NUMBER _x000D_          | PRODUCT DESCRIPTION _x000D_                                |\n",
      "|---:|:----------------------------|:-----------------------------|:-----------------------------------------------------------|\n",
      "|  0 | MDSO _x000D_                | S19-APP-MDSO-S1P1 _x000D_    | BP APPLICATION MDSO LICENSE _x000D_                        |\n",
      "|  1 | MDSO Geo Redundancy _x000D_ | S19-APP-MDSO-GR-S1P1 _x000D_ | BP APPLICATION MDSO GEO REDUNDANCY LICENSE _x000D_         |\n",
      "|  2 | NFVO _x000D_                | S19-APP-NFVO-S1P1 _x000D_    | BP APPLICATION NFVO LICENSE _x000D_                        |\n",
      "|  3 | NFVO Geo Redundancy _x000D_ | S19-APP-NFVO-GR-S1P1 _x000D_ | BP APPLICATION NFVO GEO REDUNDANCY LICENSE _x000D_         |\n",
      "|  4 | Bandwidth on Demand _x000D_ | S19-APP-BOD-S1P1 _x000D_     | BP ADD-ON APPLICATION BANDWIDTH ON DEMAND LICENSE _x000D_  |\n",
      "|  5 | 5G Network Slicing _x000D_  | S19-APP-5GSLI-S1P0 _x000D_   | BP ADD-ON APPLICATION 5G NETWORK SLICING LICENSE _x000D_   |\n",
      "|  6 | API Adaption Layer _x000D_  | S19-APP-APIGW-S1P0 _x000D_   | BP ADD-ON APPLICATION API ADAPTATION LAYER LICENSE _x000D_ |\n",
      "|  7 | TMF 633 Plugin _x000D_      | S19-APP-TMF633-S1P0 _x000D_  | BP ADD-ON SINGLE TMF 633 PLUGIN LICENSE _x000D_            |\n",
      "|  8 | TMF 638 Plugin _x000D_      | S19-APP-TMF638-S1P0 _x000D_  | BP ADD-ON SINGLE TMF 638 PLUGIN LICENSE _x000D_            |\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates_preserve_order(seq):\n",
    "    seen = set()\n",
    "    return [x for x in seq if not (x in seen or seen.add(x))]\n",
    "\n",
    "ctx = remove_duplicates_preserve_order(context)\n",
    "ctx = '\\n'.join(ctx)\n",
    "print(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = f\"\"\"\\\n",
    "<|system|> Given a part of a lengthy markdown document, answer the following question: `{query}`. Please, follow the same format as the source document given. </s>\n",
    "<|user|>\n",
    "please ONLY respond with: {{not_found_response}}, if the context does not provide the answer </s>\n",
    "CONTEXT: {ctx} \n",
    "\n",
    "<|assistant|> \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \" http://0.0.0.0:8000/answer\"\n",
    "LLM_kwargs={'max_new_tokens': 1500, 'temperature': 0.4}\n",
    "\n",
    "llm = Remote_LLM(\n",
    "        endpoint=\"http://0.0.0.0:8000/answer\",\n",
    "        generation_config=LLM_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|> Given a part of a lengthy markdown document, answer the following question: `give me a table for ciena's BPO Runtime License`. Please, follow the same format as the source document given.  \n",
      "<|user|>\n",
      "please ONLY respond with: {not_found_response}, if the context does not provide the answer  \n",
      "CONTEXT: The following tables list the licenses to run the software application. \n",
      "Table 3. BPO Runtime Licenses \n",
      "|    | PRODUCT _x000D_             | PART NUMBER _x000D_          | PRODUCT DESCRIPTION _x000D_                                |\n",
      "|---:|:----------------------------|:-----------------------------|:-----------------------------------------------------------|\n",
      "|  0 | MDSO _x000D_                | S19-APP-MDSO-S1P1 _x000D_    | BP APPLICATION MDSO LICENSE _x000D_                        |\n",
      "|  1 | MDSO Geo Redundancy _x000D_ | S19-APP-MDSO-GR-S1P1 _x000D_ | BP APPLICATION MDSO GEO REDUNDANCY LICENSE _x000D_         |\n",
      "|  2 | NFVO _x000D_                | S19-APP-NFVO-S1P1 _x000D_    | BP APPLICATION NFVO LICENSE _x000D_                        |\n",
      "|  3 | NFVO Geo Redundancy _x000D_ | S19-APP-NFVO-GR-S1P1 _x000D_ | BP APPLICATION NFVO GEO REDUNDANCY LICENSE _x000D_         |\n",
      "|  4 | Bandwidth on Demand _x000D_ | S19-APP-BOD-S1P1 _x000D_     | BP ADD-ON APPLICATION BANDWIDTH ON DEMAND LICENSE _x000D_  |\n",
      "|  5 | 5G Network Slicing _x000D_  | S19-APP-5GSLI-S1P0 _x000D_   | BP ADD-ON APPLICATION 5G NETWORK SLICING LICENSE _x000D_   |\n",
      "|  6 | API Adaption Layer _x000D_  | S19-APP-APIGW-S1P0 _x000D_   | BP ADD-ON APPLICATION API ADAPTATION LAYER LICENSE _x000D_ |\n",
      "|  7 | TMF 633 Plugin _x000D_      | S19-APP-TMF633-S1P0 _x000D_  | BP ADD-ON SINGLE TMF 633 PLUGIN LICENSE _x000D_            |\n",
      "|  8 | TMF 638 Plugin _x000D_      | S19-APP-TMF638-S1P0 _x000D_  | BP ADD-ON SINGLE TMF 638 PLUGIN LICENSE _x000D_            | \n",
      "\n",
      "<|assistant|> \n",
      "Table 3. BPO Runtime Licenses \n",
      "|    | PRODUCT _x000D_             | PART NUMBER _x000D_          | PRODUCT DESCRIPTION _x000D_                                |\n",
      "|---:|:----------------------------|:-----------------------------|:-----------------------------------------------------------|\n",
      "|  0 | MDSO _x000D_                | S19-APP-MDSO-S1P1 _x000D_    | BP APPLICATION MDSO LICENSE _x000D_                        |\n",
      "|  1 | MDSO Geo Redundancy _x000D_ | S19-APP-MDSO-GR-S1P1 _x000D_ | BP APPLICATION MDSO GEO REDUNDANCY LICENSE _x000D_         |\n",
      "|  2 | NFVO _x000D_                | S19-APP-NFVO-S1P1 _x000D_    | BP APPLICATION NFVO LICENSE _x000D_                        |\n",
      "|  3 | NFVO Geo Redundancy _x000D_ | S19-APP-NFVO-GR-S1P1 _x000D_ | BP APPLICATION NFVO GEO REDUNDANCY LICENSE _x000D_         |\n",
      "|  4 | Bandwidth on Demand _x000D_ | S19-APP-BOD-S1P1 _x000D_     | BP ADD-ON APPLICATION BANDWIDTH ON DEMAND LICENSE _x000D_  |\n",
      "|  5 | 5G Network Slicing _x000D_  | S19-APP-5GSLI-S1P0 _x000D_   | BP ADD-ON APPLICATION 5G NETWORK SLICING LICENSE _x000D_   |\n",
      "|  6 | API Adaption Layer _x000D_  | S19-APP-APIGW-S1P0 _x000D_   | BP ADD-ON APPLICATION API ADAPTATION LAYER LICENSE _x000D_ |\n",
      "|  7 | TMF 633 Plugin _x000D_      | S19-APP-TMF633-S1P0 _x000D_  | BP ADD-ON SINGLE TMF 633 PLUGIN LICENSE _x000D_            |\n",
      "|  8 | TMF 638 Plugin _x000D_      | S19-APP-TMF638-S1P0 _x000D_  | BP ADD-ON SINGLE TMF 638 PLUGIN LICENSE _x000D_            |\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Table 3. BPO Runtime Licenses \n",
      "|    | PRODUCT _x000D_             | PART NUMBER _x000D_          | PRODUCT DESCRIPTION _x000D_                                |\n",
      "|---:|:----------------------------|:-----------------------------|:-----------------------------------------------------------|\n",
      "|  0 | MDSO _x000D_                | S19-APP-MDSO-S1P1 _x000D_    | BP APPLICATION MDSO LICENSE _x000D_                        |\n",
      "|  1 | MDSO Geo Redundancy _x000D_ | S19-APP-MDSO-GR-S1P1 _x000D_ | BP APPLICATION MDSO GEO REDUNDANCY LICENSE _x000D_         |\n",
      "|  2 | NFVO _x000D_                | S19-APP-NFVO-S1P1 _x000D_    | BP APPLICATION NFVO LICENSE _x000D_                        |\n",
      "|  3 | NFVO Geo Redundancy _x000D_ | S19-APP-NFVO-GR-S1P1 _x000D_ | BP APPLICATION NFVO GEO REDUNDANCY LICENSE _x000D_         |\n",
      "|  4 | Bandwidth on Demand _x000D_ | S19-APP-BOD-S1P1 _x000D_     | BP ADD-ON APPLICATION BANDWIDTH ON DEMAND LICENSE _x000D_  |\n",
      "|  5 | 5G Network Slicing _x000D_  | S19-APP-5GSLI-S1P0 _x000D_   | BP ADD-ON APPLICATION 5G NETWORK SLICING LICENSE _x000D_   |\n",
      "|  6 | API Adaption Layer _x000D_  | S19-APP-APIGW-S1P0 _x000D_   | BP ADD-ON APPLICATION API ADAPTATION LAYER LICENSE _x000D_ |\n",
      "|  7 | TMF 633 Plugin _x000D_      | S19-APP-TMF633-S1P0 _x000D_  | BP ADD-ON SINGLE TMF 633 PLUGIN LICENSE _x000D_            |\n",
      "|  8 | TMF 638 Plugin _x000D_      | S19-APP-TMF638-S1P0 _x000D_  | BP ADD-ON SINGLE TMF 638 PLUGIN LICENSE _x000D_            |\n"
     ]
    }
   ],
   "source": [
    "bot_response = answer.split('<|assistant|>')[1].split('</s>')[0]\n",
    "print(bot_response)\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.write(bot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU safety check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the number of needed GPU ram, we calculate the following:\n",
    "\n",
    "- Input data size.\n",
    "- Model Size.\n",
    "- Intermediate Activation.\n",
    "- other stuff (framework overhead + GPU overhead).\n",
    "\n",
    "$Total GPU Memory=Model Size+Input Data Size+Intermediate Activation +Framework Overheads+GPU Overheads$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5052825600"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "free, total = torch.cuda.mem_get_info()\n",
    "(total - free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7226"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pynvml\n",
    "def get_memory_free_MiB(gpu_index):\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(int(gpu_index))\n",
    "    mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    return mem_info.free // 1024 ** 2\n",
    "\n",
    "get_memory_free_MiB(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"llmware/dragon-mistral-7b-v0\")\n",
    "tokenized = tokenizer(full_prompt, return_tensors=\"pt\")\n",
    "print(len(tokenized[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.078125"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "788 * 4 / 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tokenized[\"input_ids\"][0]).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain, RetrievalQA, ConversationChain\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrival_chain = RetrievalQA.from_chain_type(\n",
    "    llm= llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
