{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ciena/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ciena/lib/python3.11/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gradio as gr\n",
    "import os\n",
    "from backend.llm.baseLLM import Remote_LLM \n",
    "from backend.retrieval.ciena_retreival import CienaRetrieval\n",
    "from backend.embedder.baseEmbedder import baseEmbedder\n",
    "from backend.retrieval.utils import *\n",
    "from backend.retrieval.rereanker import Reranker\n",
    "from langchain.document_loaders import JSONLoader\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = baseEmbedder().embedding_function\n",
    "retriael_kwargs = {\n",
    "    \"threshold\": \"0.8\",\n",
    "    \"k\": 20,\n",
    "    \"embedder\": embedding_function,\n",
    "    \"hybrid\": True,\n",
    "}\n",
    "ciena_retreival = CienaRetrieval(**retriael_kwargs)\n",
    "reranker = Reranker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(dir= './output/'):\n",
    "    \"\"\"Load Ciena database.\"\"\"\n",
    "    \n",
    "    loaded_data = []\n",
    "    for r, d, f in os.walk(dir):\n",
    "        \n",
    "        for file in f:\n",
    "            if '.json' in file and file != 'structuredData.json':\n",
    "                file_name = os.path.join(r, file)\n",
    "                try:\n",
    "                    loader = JSONLoader(\n",
    "                        file_path=file_name,\n",
    "                        jq_schema='.[].content[]',\n",
    "                        content_key=\"text\", \n",
    "                        text_content=False,\n",
    "                        metadata_func=metadata_func)\n",
    "\n",
    "                    loaded_data.extend(loader.load())\n",
    "                    print(f\"Successfully loaded file {file_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"error in loading  file {file_name}\")\n",
    "                    print(e)\n",
    "\n",
    "    return loaded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PYTORCH_CUDA_ALLOC_CONF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPYTORCH_CUDA_ALLOC_CONF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m<frozen os>:678\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PYTORCH_CUDA_ALLOC_CONF'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(docs):\n",
    "    loaded_data = filter_empty(docs)\n",
    "    loaded_data = filter_redundant(loaded_data)\n",
    "    loaded_data = exclude_toc(loaded_data)\n",
    "    return loaded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_docs(query, docs):\n",
    "    \"\"\"Get relevant documents from Ciena database.\"\"\"\n",
    "    if len(query) == 0 or len(docs) == 0:\n",
    "        return []\n",
    "    ciena_retrieval = CienaRetrieval(**retriael_kwargs)\n",
    "    relevant_docs = ciena_retrieval.get_res(query, docs)\n",
    "    reranked_res = reranker.rerank(query, relevant_docs)\n",
    "    return reranked_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(docs, headers):\n",
    "    if len(headers) == 0:\n",
    "        return [], []\n",
    "    context, sources = ciena_retreival.get_context(docs, headers)\n",
    "    return context, sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text(history, text):\n",
    "    history = history + [(text, None)]\n",
    "    return history, gr.Textbox(value=\"\", interactive=False)\n",
    "\n",
    "def bot(history):\n",
    "    response = \"**That's cool!**\"\n",
    "    history[-1][1] = \"\"\n",
    "    for character in response:\n",
    "        history[-1][1] += character\n",
    "        time.sleep(0.05)\n",
    "        yield history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_get_src_ctx(message, seconds):\n",
    "    query = message\n",
    "    relevant_docs = get_relevant_docs(query, cleaned_db)\n",
    "    rel_headers = relevant_headers(relevant_docs)\n",
    "    rel_headers = [x for x in rel_headers if x != 'Table of Contents ']\n",
    "    context, sources = get_context(loaded_db, rel_headers)\n",
    "    return context, sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_llm_answer(question, ctx, src):\n",
    "    endpoint = \" http://0.0.0.0:8000/answer\"\n",
    "    LLM_kwargs={'max_new_tokens': 500, 'temperature': 0.5}\n",
    "\n",
    "    llm = Remote_LLM(\n",
    "        endpoint=\"http://0.0.0.0:8000/answer\",\n",
    "        generation_config=LLM_kwargs\n",
    "    )\n",
    "    ctx = ctx[len(ctx) // 2:]\n",
    "    if len(ctx) > 2000: \n",
    "        ctx = ctx[:2000]\n",
    "    prompt = f\"\"\"\n",
    "    You are a powerful AI asistant that answers only based on the given contex. If the context is not enough, you can ask for more information.\n",
    "    Given the following context {ctx}, answer the following question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    answer = llm(prompt)\n",
    "    return answer, src\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_echo(message, history):\n",
    "    ctx, src = main_get_src_ctx(message, 3)\n",
    "    # convert list ctx to string\n",
    "    ctx =' '.join(ctx)\n",
    "    answer, src = gt_llm_answer(message, ctx, src)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded file ./output/17-Dec-UAA_21.10_rhel_install_guide.pdf/17-Dec-UAA_21.json\n",
      "Successfully loaded file ./output/10Aug-BP_Engineering_guide.pdf/10Aug-BP_Engineering_guide.json\n",
      "Successfully loaded file ./output/uaa-admin-guide.pdf/uaa-admin-guide.json\n",
      "Successfully loaded file ./output/5G_Netwrok_Slicing_Installation_Guide_21.06.pdf/5G_Netwrok_Slicing_Installation_Guide_21.json\n",
      "Successfully loaded file ./output/Blue Planet Cloud Deployment Guide 20.06.pdf/Blue Planet Cloud Deployment Guide 20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded file ./output/Blue_Planet_Engineering_Guide_2208_Issue_1-0.pdf/Blue_Planet_Engineering_Guide_2208_Issue_1-0.json\n",
      "Successfully loaded file ./output/Blue_Planet_Engineering_Guide_2208.pdf/Blue_Planet_Engineering_Guide_2208.json\n",
      "Successfully loaded file ./output/Blue_Planet_MLA_Cloud_Deployment_Guide.pdf/Blue_Planet_MLA_Cloud_Deployment_Guide.json\n",
      "Successfully loaded file ./output/BP_Engineering_Guide.pdf/BP_Engineering_Guide.json\n",
      "Successfully loaded file ./output/25Aug_Blue_Planet_Engineering_Guide_2208.pdf/25Aug_Blue_Planet_Engineering_Guide_2208.json\n",
      "Successfully loaded file ./output/25July-BP_Engineering_guide.pdf/25July-BP_Engineering_guide.json\n",
      "Successfully loaded file ./output/24-Jan-450-3704-300-2110-UAA_21.10_rhel_install_guid_1-0.pdf/24-Jan-450-3704-300-2110-UAA_21.json\n",
      "Successfully loaded file ./output/updateddraft_5g_nsinstallguide_21.06.pdf/updateddraft_5g_nsinstallguide_21.json\n",
      "Successfully loaded file ./output/BP_Security_Guide_2304_1-0.pdf/BP_Security_Guide_2304_1-0.json\n",
      "Successfully loaded file ./output/11Aug-BP_Engineering_guide.pdf/11Aug-BP_Engineering_guide.json\n",
      "Successfully loaded file ./output/450-3702-420-2202_BPO_Security_Guide.pdf/450-3702-420-2202_BPO_Security_Guide.json\n",
      "Successfully loaded file ./output/450-3708-523-2106_Blue_Planet_5G-Network_Slicing_IAS_Installation_Guide_Issue-1.pdf/450-3708-523-2106_Blue_Planet_5G-Network_Slicing_IAS_Installation_Guide_Issue-1.json\n",
      "Successfully loaded file ./output/16Aug-BP_Engineering_Guide.pdf/16Aug-BP_Engineering_Guide.json\n",
      "Successfully loaded file ./output/old.pdf/old.json\n",
      "Successfully loaded file ./output/Blue_Planet_Engineering_Guide_2208_Issue_1-1.pdf/Blue_Planet_Engineering_Guide_2208_Issue_1-1.json\n"
     ]
    }
   ],
   "source": [
    "loaded_db = load_db()\n",
    "cleaned_db = clean(loaded_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"ًgive me a table for ciena's BPO Runtime License\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = get_relevant_docs(query, cleaned_db)\n",
    "rel_headers = relevant_headers(relevant_docs)\n",
    "context, sources = get_context(loaded_db, rel_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue Planet UAA RHEL/CentOS/Linux Installation Guide \n",
      "Blue Planet Release 21.10 \n",
      "December 2021: Issue 1.0 \n",
      "sudo dd if=rhel-server-7.7-x86_64-dvd.iso of=/dev/sdb bs=8M \n",
      "sudo fdisk -l \n",
      "diskutil list \n",
      "sudo dd if=rhel-server-7.7-x86_64-dvd.iso of=/dev/disk4 bs=4096 \n",
      "./bpi --site /opt/ciena/loads/21.10/lineup-uaa-base-single-rhel.yml \n",
      "./bpi --site /opt/ciena/loads/21.10/lineup-uaa-base-multi-rhel.yml \n",
      "./bpi --site /opt/ciena/loads/21.10/lineup-uaa-all-single-rhel.yml \n",
      "./bpi --site /opt/ciena/loads/21.10/lineup-uaa-all-multi-rhel.yml \n",
      "If you are provisioning your own NTP timing, add the following playbook arguments: \n",
      "./bpi --site /opt/ciena/loads/21.10/<lineup_file> --playbook-args='--skip-tags ntp' \n",
      "./bpi --install /opt/ciena/loads/21.10/lineup-uaa-base-single-rhel.yml \n",
      "./bpi --install /opt/ciena/loads/21.10/lineup-uaa-base-multi-rhel.yml \n",
      "./bpi --install /opt/ciena/loads/21.10/lineup-uaa-all-single-rhel.yml \n",
      "./bpi --installs /opt/ciena/loads/21.10/lineup-uaa-all-multi-rhel.yml \n",
      "The lineup files contain a customer-specific list of BPUAA solutions to install. The lineup files apply to all supported operating systems: RHEL, Oracle Linux, and CentOS. \n",
      "Blue Planet Engineering Guide \n",
      "Blue Planet Engineering 22.08 \n",
      "2022: Draft \n",
      " \n",
      "Cluster Autoscaler is a Kubernetes component that automatically adjusts the size of the Kubernetes cluster based on the utilization of Pods and Nodes in your cluster. \n",
      "Host 0 \n",
      "250 \n",
      "600 \n",
      "SOO and BPI \n",
      "BPI and MDSO \n",
      "Host 1 \n",
      "Host 2 \n",
      "Release 23.04 \n",
      "Issue 1.0 | February 2023 | 450-3701-500-2304 \n",
      "Cell Count \n",
      "Column Count \n",
      "PDF Cell Count \n",
      "PDF Column Count \n",
      "PDF Row Count \n",
      "Row Count \n",
      "Zip Row Count \n",
      "Date with Short Week, Month and Time \n",
      "Generic Temporal Format \n",
      "Generic Temporal Format with timezone \n",
      "Locale \n",
      "Select the language in which the fields and messages in Blue Planet Inventory are to be displayed. For details regarding setup and configuration, refer to BPI Localization Support Technical Guide. \n",
      "Preferred Generic Temporal Format \n",
      "Select the format to define date and time points using calendar units . \n",
      "Short Date Format \n",
      "Time Format \n",
      "User TimeZone \n",
      "Server TimeZone \n",
      "Select the timezone of the server. \n",
      "Miscellaneous \n",
      "Contains options for miscellaneous features. \n",
      "LoginPopup Attempts \n",
      "It is a graphical user interface ( GUI ) display area, usually a small window, that suddenly appears (\"pops up\") in the foreground of the visual interface. \n",
      "Page Container \n",
      "Enables you to customize the features related to the pages to be displayed in Blue Planet Inventory \n",
      "Maximum number of tabs \n",
      "Define the maximum number of the tabs that can be displayed at one time. \n",
      "Open Page in a New Tab \n",
      "If enabled, a new page opens in a new tab otherwise, a new page opens in the currently active page. \n",
      "Work Time \n",
      "It shows the work time, day, week of the UAA. \n",
      "First day of Week \n",
      "First week of year \n",
      "It shows the first week of the year. \n",
      "Work week \n",
      "It shows the work day of the week. \n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?> <ext-db-config> <config name=\"oracle\" driver-path=\"oracle.jdbc.OracleDriver\"/> </ext-db-config> \n",
      "{\"data\": {\"type\": \"useCase\", \"attributes\": {\"name\": \"UAA Alarms Noise Reduction Model performance evaluation use case template\", \"description\": \"model performance evaluation use case template\", \"additionalAttributes\": {\"script\": \"spark/src/main/python/training/bpuaa_model_evaluation_v1.sh\", \"execution\": {\"executionIntervalMinutes\": 0, \"maxRetriesPerAttempt\": 5, \"durationBetweenFailedAttemptsMinutes\": 5}, \"dynamic_parameters\": [\"postgres-database-url\", \"postgres-user\", \"postgres-pw\", \"bpuaa-postgres-database-url\", \"bpuaa-postgres-user\", \"bpuaa-postgres-pw\"], \"parameters\": {\"dataset-name\": \"alarms_test_data_model_evaluation.parquet\", \"model-to-evaluate\": \"xgboost_alarms_classifier_model.onnx\", \"data-range-in-days\": 30}}, \"rootcauses\": []}}}\n",
      "{ \n",
      "\"data\": { \n",
      "\"type\": \"useCase\", \n",
      "\"attributes\": { \n",
      "\"name\": \"UAA Alarms Noise Reduction use case template\", \n",
      "\"description\": \"a streaming use case template\", \n",
      "\"additionalAttributes\": { \n",
      "\"script\": \"spark/src/main/python/inference/bpuaa_alarms_spark_inference_v1.sh\", \"execution\": { \n",
      "\"executionIntervalMinutes\": 0, \n",
      "\"maxRetriesPerAttempt\": 5, \n",
      "\"durationBetweenFailedAttemptsMinutes\": 5 \n",
      "}, \n",
      "\"dynamic_parameters\": [ \n",
      "\"kafka-broker\", \n",
      "\"postgres-database-url\", \"postgres-user\", \"postgres-pw\" ], \"parameters\": { \"topic-in\": \"com.ciena.bp.uaa.alarms.in\", \"topic-out\": \"com.ciena.bp.uaa.alarmModification\", \"input-shape\": [ 1, 3 ], \"model-path\": \"/tmp/bpa-nhp-catalog/models/files/xgboost_alarms_classifier_model.onnx\", model-name\": \"xgboost_alarms_classifier_model.onnx\", \"model-format\": \"onnx\", \"model-backend\": \"onnx\", \"model-type\": \"classification\", \"features\": [ \"perceivedSeverity\", \"specificProblem\", \"profileId\" ], \"alarms\": [ \"Important\", \"Noise\" ], \"multilabel\": \"false\", \"threshold\": \"0.021\", \"inference-path\": \"/tmp/bpa-nhp-libs/bpaengine-0.1.15-py3.6.egg\", \"checkpoint-location-prefix\": \"/tmp/inference\", \"alarm-specificproblem-le\" : \"/tmp/bpa-nhp-catalog/models/files/sp_le.pkl\", \"alarm-profileid-le\" : \"/tmp/bpa-nhp-catalog/models/files/pro_le.pkl\" } }, \"rootcauses\": [ { \"name\": \"Important\", \"description\": \"Important alarm\" }, { \"name\": \"Noise\", \"description\": \"Noise alarm\" } ] } } } \n",
      "solution_app_stop artifactory.ciena.com.blueplanet.uaa:21.10.14 uaa-med-pme \n",
      "Command to list dependent containers of pm-db: \n",
      "api containers <container_name> nbis get \n",
      "api containers uaa-pm-db_0.3.5_0 nbis get \n",
      "python3 pmDbPasswordManager.py \n",
      "When prompted, enter the appropriate username and new password \n",
      "solution_app_restart artifactory.ciena.com.blueplanet.uaa_pm_storage:21.10.14 uaa-pm-db \n",
      "Start all the dependent containers: \n",
      "solution_app_start artifactory.ciena.com.blueplanet.<solution_name> <container_name> \n",
      "solution_app_start artifactory.ciena.com.blueplanet.uaa:21.10.14 uaa-med-pme \n",
      "Command to list dependent containers of graph-db: \n",
      "api containers uaa-graph-db_0.3.9_0 nbis get \n",
      "python3 graphDBPasswordManager.py \n",
      "solution_app_restart artifactory.ciena.com.blueplanet.uaa_storage:21.10.14 uaa-graph-db \n",
      "solution_app_start artifactory.ciena.com.blueplanet.<solution_name><container_name> \n",
      "api containers uaa-core-db_0.3.9_0 nbis get \n",
      "Enter the uaa-core-db container. \n",
      "¬ pgSuper ¬ ALTER USER \"<user>\" WITH PASSWORD '<new password>' ; \n",
      "solution_app_restart artifactory.ciena.com.blueplanet.uaa_storage:21.10.14 uaa-core-db \n",
      "solution_app_start \n",
      "artifactory.ciena.com.blueplanet.<solution_name><container_name> \n",
      "vi\n",
      " /etc/hosts \n",
      "Provide IP of VM with host name of external kafka. \n",
      "<external kafka ip> <Host name of external kafka ip> \n",
      "Example: 10.107.3.59 ip-10-107-3-59.ap-south-1.compute.internal \n",
      "Repeat the complete configuration for all the instances of UAA-Kafka-Bridge. \n",
      "5G Network Slicing Intelligent Automation Solution Installation Guide \n",
      "Blue Planet Release 21.06 \n",
      "February 2022: Issue 1.0 \n",
      "sudo dd if=rhel-server-7.7-x86_64-dvd.iso of=/dev/sdb bs=8M sudo fdisk -l \n",
      "diskutil list sudo dd if=rhel-server-7.7-x86_64-dvd.iso of=/dev/disk4 bs=4096 \n",
      "\n",
      "\n",
      "\n",
      "Configuring the 5G Network Slicing IAS host(s) creates the following directories and ensures they are owned by bpuser: \n",
      "Complete the following procedure to configure the 5G Network Slicing IAS host(s) for the 5G Network Slicing IAS software installation. This is a mandatory procedure. This procedure also performs minor configuration changes including updates to syslog, rsyslog, sshd, and NTP to prepare the host for 5G Network Slicing IAS installation. \n",
      "Blue Planet Cloud Deployment Guide \n",
      "Blue Planet Release 20.06 \n",
      "August 2020: Issue 1 \n",
      "The following output displays for AWS: \n",
      "root# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT nvme0n1 259:1 0 50G 0 disk \\u2514\\u2500nvme0n1p1 259:2 0 50G 0 part / nvme1n1 259:0 0 1.2T 0 disk The following output displays for Azure: \n",
      "NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 30G 0 disk \\u251c\\u2500sda1 8:1 0 500M 0 part /boot \\u251c\\u2500sda2 8:2 0 29G 0 part / \\u251c\\u2500sda14 8:14 0 4M 0 part \\u2514\\u2500sda15 8:15 0 495M 0 part /boot/efi sdb 8:16 0 64G 0 disk \\u2514\\u2500sdb1 8:17 0 64G 0 part /mnt/resource sdc 8:32 0 1.2T 0 disk sr0 11:0 1 628K 0 rom \n",
      "In the above output, nvme1n1 and sdc are the second 1.2 TB storage volume in AWS and Azure, respectively \n",
      "August 2022: 1.0 \n",
      "Blue Planet MLA Cloud Deployment Guide (Geo Redundancy) \n",
      "Blue Planet Release 22.02 \n",
      "April 2022: Issue 1 \n",
      "pvcreate /dev/nvme2n1 \n",
      "vgextend vg_sys /dev/nvme2n1 \n",
      "b. Azure: \n",
      "[root]# pvcreate /dev/sdc \n",
      "Physical volume \"/dev/sdc\" successfully created. \n",
      "[root]# vgcreate vg_sys /dev/sdc \n",
      "vg_sys 1 0 0 wz--n- 1.20t 1.20t \n",
      ";create a swap file sudo dd if=/dev/zero of=/mnt/resource/swapfile count=8192 bs=1MiB ;set up the file for swapspace sudo mkswap /mnt/resource/swapfile ;set appropriate permissions on the swapfile sudo chmod 600 /mnt/resource/swapfile ;automatically mount the file as swap area on startup echo '/mnt/resource/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab \n",
      "swapon -a \n",
      "free -m \n",
      "January 2022: Issue 1.0 \n",
      "5G Network Slicing IAS Installation Guide \n",
      "md5sum LinuxIntel_2021_xx_x.tar \n",
      "sudo dd if=rhel-server-7.6-x86_64-dvd.iso of=/dev/sdb bs=8M sudo fdisk -l \n",
      "sudo dd if=rhel-server-7.6-x86_64-dvd.iso of=/dev/disk4 bs=4096 \n",
      "Extract the bpi-21.06-xx.sh file you transferred in step 5. \n",
      "Extract the <bp_solution>-21.06.xx.xxx.tar file you transferred in step 7. \n",
      "tar -xf <bp_solution>-2106_21.06.xx-xxx.tar \n",
      "13. \n",
      "Extract the 3gpp-<version>.jar file you transferred in step 8. \n",
      "jar xf 3gpp-<version>.jar \n",
      "Issue 1.0 | April 2023 | 450-3709-420-2304 \n",
      "NEWUID=16385 NEWUSER=bpuser1 ldapmodify -x -D \"cn=admin,dc=lonlab,dc=ciena,dc=com\" -W <<EOF dn: uid=$NEWUSER,ou=People,dc=lonlab,dc=ciena,dc=com changetype: add objectClass: inetOrgPerson objectClass: posixAccount objectClass: shadowAccount objectClass: BluePlanet uid: $NEWUSER mail: bptest1@lonlab.ciena.com sn: $NEWUSER givenName: user cn: $NEWUSER displayName: $NEWUSER uidNumber: $NEWUID gidNumber: $NEWUID userPassword: secret gecos: $NEWUSER loginShell: /bin/bash homeDirectory: /home/$NEWUSER BPtenant: master dn: cn=BP-Application-Admin,ou=Group,dc=lonlab,dc=ciena,dc=com changetype: modify add: memberUid memberUid: $NEWUSER EOF \n",
      "Tron requires the mail attribute which must be unique. You can omit all other fields that are optional for the posixAccount objectClass, although sn and givenName are shown in the BP Web UI and make for easy identification of user records. \n",
      "curl -k -H \"Content-Type:application/json\" -d \n",
      "'{\"username\":\"admin\",\"password\":\"adminpw\", \"tenant\":\"master\"}' -X POST https://10.206.30.107/tron/api/v1/tokens | python -m json.tool \n",
      "A response containing text similar to the following displays: \n",
      "{ \"createdTime\": \"2016-05-11T17:30:05.812645Z\", \"failedLoginAttempts\": 0, \"lastSuccessIpAddress\": \"10.206.30.107\", \"lastSuccessLogin\": \"2016-11-05 17:29:58+00:00\", \"sessionId\": \"85f45768-7223-4bed-a9b6-92725208a3a5\", \"timeout\": 86400, \"token\": \"78b97d242d3bcac14b87\", \"user\": \"5d5c14e2-96f4-45dd-9937-84d0d6cc9c40\" } \n",
      "where the Blue Planet server with IP address 10.206.30.107 creates the token \n",
      "“78b97d242d3bcac14b87”. You can also replace the IP address in the command with the fully-qualified domain name (FQDN). \n",
      "curl -H \"Content-Type: application/json\" -k -H \"Authorization: token 78b97d242d3bcac14b87\" -X GET https://10.200.33.106/tron/api/v1/ldap-configs | python -m json.tool \n",
      "A response similar to the following displays: \n",
      "{  \"count\": 2,  \"previous\": null,  \"results\": [  {   \"description\": \"\",   \"createdTime\": \"2018-11-16T00:33:14Z\",   \"modifiedTime\": \"2018-11-16T00:45:26Z\",   \"uuid\": \"ff1fecd5-731c-4a4e-bed1-37e2b652712f\",   \"name\": \"primary_config\",   \"enabled\": true,   \"serverIp\": \"ldap://10.200.33.106\",   \"enableSsl\": false,   \"sslLevel\": \"ALLOW\",   \"domainSearchUser\": \"CIENA\\\\userxyz\",   \"enableReferrals\": false,   \"baseDn\": \"DC=ciena,DC=com\",   \"userNameAttribute\": \"sAMAccountName\",   \"tenantAttribute\": \"\",   \"accessibleTenantsAttribute\": \"\",   \"groupNameAttribute\": \"cn\",   \"groupObjectFilter\": \"(objectClass=Group)\",   \"roleMap\": \"{\\\"list.PQA Team\\\":{\\\"app_name\\\":\\\"BluePlanet\\\",\\\"uac_role_name\\\":\\\"Application admin\\\"}}\" },    {      \"description\": \"\",      \"createdTime\": \"2018-06-13T19:30:58Z\",      \"modifiedTime\": \"2018-06-13T19:30:58Z\",      \"uuid\": \"f23b974c-93dd-4df3-95e4-30a405ad94cf\",      \"name\": \"backup_config\",      \"enabled\": false,      \"serverIp\": \"\",      \"enableSsl\": false,      \"sslLevel\": \"ALLOW\",      \"domainSearchUser\": \"\",      \"enableReferrals\": false,      \"baseDn\": \"\",      \"userNameAttribute\": \"sAMAccountName\",      \"tenantAttribute\": \"\",      \"accessibleTenantsAttribute\": \"companyA,companyB\",      \"groupNameAttribute\": \"cn\",      \"groupObjectFilter\": \"(objectClass=Group)\",      \"roleMap\": \"{}\"    }  ],  \"page\": 1,  \"next\": null } \n",
      "Blue Planet Orchestration Security Guide \n",
      "April 2022: 450-3702-420-2202 Issue 1.0 \n",
      "curl -k -H \"Content-Type:application/json\" -d '{\"username\":\"admin\",\"password\":\"adminpw\", \"tenant\":\"master\"}' -X POST https://10.206.30.107/tron/api/v1/tokens | python -m json.tool \n",
      "To configure the hosts: \n",
      "./bpi --site /opt/ciena/loads/21.06/<lineup_file> --playbook-args='--skip -tags ntp' \n",
      "October 2022: 1.1 \n",
      "\n",
      "3. \n",
      "|    | NOTE _x000D_   | In case of errors, you need to install BPUAA afresh. For more information, see Clean-up BPUAA installation. _x000D_                                                                 |\n",
      "|---:|:---------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|  0 | NOTE _x000D_   | The lineup files contain a customer-specific list of BPUAA solutions to install. The lineup files apply to all supported operating systems: RHEL, Oracle Linux, and CentOS. _x000D_ |\n",
      "NOTE \n",
      "If no failures occur, indicated by failed=0, continue with the next step. If failures occurred, contact Ciena Customer Support for guidance. \n",
      "BPI \n",
      "8 \n",
      "64 GB \n",
      "32 \n",
      "128 GB \n",
      "User, System and Global Preference \n",
      "2. \n",
      "8. \n",
      "7. \n",
      "a. \n",
      "AWS: \n",
      "[root]# pvcreate /dev/nvme1n1 \n",
      "Physical volume \"/dev/nvme1n1\" successfully created. \n",
      "[root]# vgcreate vg_sys /dev/nvme1n1 \n",
      "Volume group \"vg_sys\" successfully created \n",
      "[root]# vgs \n",
      "VG #PV #LV #SN Attr VSize VFree \n",
      "vg_sys 1 0 0 wz--n- 1.17t 1.17t \n",
      "cd /home/bpadmin \n",
      "10. \n",
      "bash bpi-{bpi-version}.sh \n",
      "11. \n",
      "Change to the \n",
      "/opt/ciena/loads/21.06\n",
      " directory: \n",
      "cd /opt/ciena/loads/21.06 \n",
      "12. \n",
      "sudo dd if=</path to image>.iso of=/dev/disk4 bs=4096 \n",
      "Output, similar to the following, indicates whether the configuration succeeded: \n",
      "PLAY RECAP ***************************************************************************** *** <host>  \n",
      ": ok=102  \n",
      "changed=47  \n",
      "unreachable=0 failed=0 \n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates_preserve_order(seq):\n",
    "    seen = set()\n",
    "    return [x for x in seq if not (x in seen or seen.add(x))]\n",
    "\n",
    "ctx = remove_duplicates_preserve_order(context)\n",
    "ctx = '\\n'.join(ctx)\n",
    "print(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = f\"\"\"\\\n",
    "<|system|> Based on the context below, answer the following question: `{query}`. </s>\n",
    "<|user|>\n",
    "please ONLY respond with: {{not_found_response}}, if the context is not enough </s>\n",
    "CONTEXT: {ctx} \n",
    "\n",
    "<|assistant|> \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = f\"\"\"\\\n",
    "<|system|> Given a part of a lengthy markdown document, answer the following question: `{query}`. Please, follow the same format as the source document given. </s>\n",
    "<|user|>\n",
    "please ONLY respond with: {{not_found_response}}, if the context does not provide the answer </s>\n",
    "CONTEXT: {ctx} \n",
    "\n",
    "<|assistant|> \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \" http://0.0.0.0:8000/answer\"\n",
    "LLM_kwargs={'max_new_tokens': 1500, 'temperature': 0.4}\n",
    "\n",
    "llm = Remote_LLM(\n",
    "        endpoint=\"http://0.0.0.0:8000/answer\",\n",
    "        generation_config=LLM_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|> Given a part of a lengthy markdown document, answer the following question: `ًHow to create the bpadmin user`. Please, follow the same format as the source document given.  \n",
      "<|user|>\n",
      "please ONLY respond with: {not_found_response}, if the context does not provide the answer  \n",
      "CONTEXT: The bpadmin user is given full passwordless sudo privileges. For multi-host installations, use the same bpadmin password on all hosts. The bpadmin user with full sudo access is needed to install the BPUAA applications and to create the bpuser, which has limited sudo access. \n",
      "Complete the following procedure to create the bpadmin user on each host where you will install BPUAA. This is a mandatory procedure. \n",
      "Before you begin, ensure that you have a password that you want to assign for the bpadmin user. \n",
      "The bpadmin user is given full passwordless sudo privileges. For multi-host installations, use the same bpadmin password on all hosts. The bpadmin user with full sudo access is needed to install the 5G Network Slicing IAS applications and to create the bpuser, which has limited sudo access. \n",
      "Complete the following procedure to create the bpadmin user on each host where you will install 5G Network Slicing IAS. This is a mandatory procedure. \n",
      "To create the bpadmin user: \n",
      "11. \n",
      "For multi-host deployments, repeat this procedure on each host. Use the same bpadmin password on all hosts. \n",
      "After you complete the 5G Network Slicing IAS installation, you can optionally delete the bpadmin user and use bpuser for ongoing Docker, solman, and bp2-site operations. \n",
      "Complete the following procedure to create the bpadmin user on each host where you will install the MDSO/NFVO. The bpadmin user is given full passwordless sudo privileges. For multi-host installations, use the same bpadmin password on all hosts. The bpadmin user with full sudo access is needed to install the MDSO/NFVO applications and to create the bpuser, which has limited sudo access. \n",
      "This section covers how to create the bpadmin user. The bpadmin user with full sudo access is required to install ROA applications and then create the bpuser, which has limited sudo access. \n",
      "For multi-host deployment, create a bpadmin user on each host where you want to install ROA. Use the same bpadmin password on all hosts. \n",
      "Complete the following procedure to create the bpadmin user on each host where you will install 5G Network Slicing IAS. \n",
      "Before you begin, ensure that you have a password that you want to assign to the bpadmin user. \n",
      "\n",
      "groupadd bpadmin \n",
      "3. \n",
      "Create the bpadmin user: \n",
      "useradd -d <user_home> -g bpadmin -s /bin/bash -m bpadmin \n",
      "|    | where _x000D_       | Unnamed: 1                                                                                                                                                                                                                                 |\n",
      "|---:|:--------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|  0 | <user_home> _x000D_ | Is the directory of the bpadmin user. Set /home/bpadmin as the bpadmin user home directory. If you use another directory, adapt the steps through the 5G Network Slicing IAS installation to point to that directory, as required. _x000D_ |\n",
      "where \n",
      "<user_home> \n",
      "4. \n",
      "Set the password for the bpadmin user: \n",
      "passwd bpadmin \n",
      "echo \"bpadmin ALL=(ALL) NOPASSWD: ALL\" >> /etc/sudoers.d/bpadmin \n",
      "exit \n",
      "sudo su -\n",
      "|    | COMMAND _x000D_                                             | ACTION _x000D_                                                                |\n",
      "|---:|:------------------------------------------------------------|:------------------------------------------------------------------------------|\n",
      "|  0 | groupadd bpadmin                                            | Create a new group. _x000D_                                                   |\n",
      "|  1 | useradd -d <user_home> -g bpadmin -s /bin/bash -m bpadmin   | Create the bpadmin user. _x000D_                                              |\n",
      "|  2 | passwd                                                      | Set the password for the bpadmin user. _x000D_                                |\n",
      "|  3 | echo \"bpadmin ALL=(ALL) NOPASSWD: ALL\" >> /etc/sudoers.d/   | Assign the bpadmin user full sudo privileges. _x000D_                         |\n",
      "|  4 | sed -i \"s/^.*requiretty/#Defaults requiretty/\" /etc/sudoers | Disable the TTY requirement. _x000D_                                          |\n",
      "|  5 | exit                                                        | Exit the root user. _x000D_                                                   |\n",
      "|  6 | sudo su -                                                   | Verify that you can use the sudo command without entering a password. _x000D_ |\n",
      "You must have a password that you want to assign for the bpadmin user.  \n",
      "\n",
      "<|assistant|> \n",
      "Please provide the password for the bpadmin user.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "You can deploy Blue Planet products using the Blue Planet native platform, or using the Kubernetes open source container orchestration platform.\n"
     ]
    }
   ],
   "source": [
    "bot_response = answer.split('<|assistant|>')[1].split('</s>')[0]\n",
    "print(bot_response)\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.write(bot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU safety check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the number of needed GPU ram, we calculate the following:\n",
    "\n",
    "- Input data size.\n",
    "- Model Size.\n",
    "- Intermediate Activation.\n",
    "- other stuff (framework overhead + GPU overhead).\n",
    "\n",
    "$Total GPU Memory=Model Size+Input Data Size+Intermediate Activation +Framework Overheads+GPU Overheads$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5052825600"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "free, total = torch.cuda.mem_get_info()\n",
    "(total - free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7226"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pynvml\n",
    "def get_memory_free_MiB(gpu_index):\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(int(gpu_index))\n",
    "    mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    return mem_info.free // 1024 ** 2\n",
    "\n",
    "get_memory_free_MiB(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2099\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"llmware/dragon-mistral-7b-v0\")\n",
    "tokenized = tokenizer(full_prompt, return_tensors=\"pt\")\n",
    "print(len(tokenized[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.078125"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "788 * 4 / 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tokenized[\"input_ids\"][0]).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain, RetrievalQA, ConversationChain\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrival_chain = RetrievalQA.from_chain_type(\n",
    "    llm= llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
